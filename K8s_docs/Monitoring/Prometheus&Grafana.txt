# Monitoring Application on k8s and monitoring cluster(underlying infra)
* Basic archetecture
  - it has prometheus server(http server, time series DB, Retrivel) 
     - http server - u can ask for data to this server with promql -->to Grafana, prometheus UI, API clients
     - TSDB - to store metrics
     - Retrival - to retrive data from configured targets.
  - Alert manager - prom. will push server data to Alert manager for any breach --> mail, slack

- We can install prometheus on a server and configure it monitor k8s Or we can directly install prometheus on k8s and configure.
- Prometheus is close to apps it needs to monitor and no need of different server.
- We can monitor:
    - applications
    - controlplane components - api server, coredns, kube-scheduler..
    - Kubelet - exposing container metrics.
    - kube state metrics - cluster level metrics (deployment/pod....metrics)
- Need Node exporter - Run on all nodes for host metrics (cpu, mem, network) - use deamonset
- Need kube state metrics pods.
- Service discovery - use k8s API to discover a list of all targets that we need to scrape.

# Prometheus deployment
- Use helm chart.
 - https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack
 - it deploy everything that we need to deploy and run prometheus (deploy prometheus operator,alert manager, service/pod monitor, push gateway...) * operator are for CRD's.
   - check operator - https://github.com/prometheus-operator/prometheus-operator
- kind: Prometheus

# Install Helm
 - Go to - https://helm.sh/docs/intro/install
   - $ curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
     $ chmod 700 get_helm.sh
     $ ./get_helm.sh
# Prometheus
- helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
- helm repo update
- check for charts downloaded -helm search repo
- helm show values prometheus-community/kube-prometheus-stack > values.yaml    ---change values if u want. this is chartname -prometheus-community/kube-prometheus-stack
- if done any changes - helm install <release-name> <chart-name> -f values.yaml
- helm install <some-release-name-prometheus> prometheus-community/kube-prometheus-stack
- helm install <some-release-name-prometheus> prometheus-community/kube-prometheus-stack --debug (use debug to see details of install/upgrade)
- kubectl get ds  - o/p kubectl get ds
* (Due to a known bug you might need to patch the Prometheus node exporter DaemonSet using below command. )
- kubectl patch ds prometheus-prometheus-node-exporter --type "json" -p '[{"op": "remove", "path" : "/spec/template/spec/containers/0/volumeMounts/2/mountPropagation"}]'  
* Things deployed after installations.
 - statefulset (Prometheus server 2 , alert-manager 2 )
 - deployment ( 1 kube state metrics, 1 pod Prometheus operator,3 pod grafana)
 - deamonset 1 per node (node-exporter) 
 - services for all as cluster IP, so will need ingress or LB
   - if we do a port frowarding - kubectl port-forward <prometheus-pod> 9090 --o/p --> will give 127.0.0.1:9090 where u will get prometheus UI. OR
   - kubectl expose service prometheus-kube-prometheus-prometheus --type=NodePort --name=prom-service --port=9090 --target-port=9090 -n monitoring  
      --access via IP:nodeport
   - go to status --> configuration-->its a file(go to scrape config -->kubernetes_sd_configs: uses endpoins to scrape data.) 
                    *Endpoints have access to everything in k8s, it is used for service discovery.

* deploy ur application ok k8s

* Configure prometheus to scrape ur application or other targets
 - 1st way (less ideal way) - helm show values prometheus-community/kube-prometheus-stack > values.yaml
           - go to file -> search Additional scrape configs --> uncomment job/jobs and remove [] or add a job
                         - scrape_configs:
                           - job_name: 'your-app'
                             static_configs:
                              - targets: ['your-app-service:8080']

 - 2nd way - kubectl get crd --> prometheus monitioring & prometheusrules monitioring(to add scrape targets)
             - this is a custom resource - servicemonitors.monitoring.coreos.com for service monitoring
           - service monitor helps to add targets without touching prometheus config file.
            - create object of kind:ServiceMonitor and configure it look for a service, configure <port-name>, and jobLabel/job
    * While creating serviceMonitor keepsits lables- release: prometheus as prometheus by default looks for serviceMonitor with that lable.
      -kubectl get prometheuses.monitoring.cores.com -o yaml-->search release:prometheus, its value should match with lable of serviceMonitor(release:prometheus)
      - kubectl get servicemonitor (there are many by default for k8s components & prometheus components)
 * Note - for Prometheus to scrape metrics from your application running as a pod in Kubernetes, you typically need to expose a metrics endpoint in your 
          application and configure Prometheus to scrape that endpoint in serviceMonitor. 
 * go to UI-->status-->targets-->u will see ur job
   - on Main page -> search --> {job="node-api"}


# Basic folder structure for prometheus
prometheus/
|-- prometheus.yml
|-- alertmanager/
|   |-- alertmanager.yaml
|   |-- alertmanagerConfig.yaml
 - alertmanager is seperate component
 - alertmanager.yaml has global configurations, routes, and inhibit rules.
 - alertmanagerConfig.yaml used for more advanced configurations beyond the basic setup.(adding email.slack)

* Add Rules --create CRD prometheusrules (similar labes operation as serviceMonitor)
 - Rules - to add alerts rules
 - kind: PrometheusRule
 - kubectl get prometheusrules 
 - UI-->status -->rules
* For serviceMonitor and alert rules see prometheus-rules file (it has yaml)

* Alertmanager Rules - create CRD AlertManagerConfig and apply it but first update/add alertmanagerConfigSelector
 - kubectl get alertmanagers.monitoring.coreos.com -o yaml 
 - prometheus by default deos not gives lable selector for alertmanagers.monitoring.coreos.com
 - so helm show values prometheus-community/kube-prometheus-stack > values.yaml --> open the file and add 
      - alertmanagerConfigSelector:      (delete the default {})
             matchLables:
               resource: prometheus
 - then helm upgrade <some-release-name-prometheus> prometheus-community/kube-prometheus-stack -f value.yaml -n <namespace>
 - kubectl port-forward service/alertmanager-operated 9093

# Can go to grafana directly
# Install metrics server
- helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/
- helm install metrics-server metrics-server/metrics-server -n kube-system
- kubectl get pods -n kube-system | grep metrics-server


## Grafana is installed with prometheus chart no need to install it again 
- kubectl expose service prometheus-grafana --type=NodePort --name=grafana-service-1 --port=80 --target-port=3000 -n monitoring
- kubectl get secret prometheus-grafana -n monitoring -o yaml
- echo “password_value” | openssl base64 -d ; echo
- echo “username_value” | openssl base64 -d ; echo

# Setting Grafana
- helm repo add grafana https://grafana.github.io/helm-charts
- helm repo update
- helm install grafana grafana/grafana
- kubectl expose service grafana — type=NodePort — target-port=3000 — name=grafana-ext
- kubectl get secret — namespace default grafana -o yaml
- echo “password_value” | openssl base64 -d ; echo
- echo “username_value” | openssl base64 -d ; echo
* Add prometheus data source into Grafana dashboard
 - follow the steps from here - https://medium.com/globant/setup-prometheus-and-grafana-monitoring-on-kubernetes-cluster-using-helm-3484efd85891

* Setting gmail/slack with alertmanager
- kubectl get svc --(expose as nodeport prometheus-alertmanager)
- access UI - IP:service-port -->under status --> config(this needs to chnage from cmdline config map)
- kubectl get cm -->prometheus-alertmanager (need to make changes here for email notification)
- kubectl edit cm prometheus-alertmanager --> add under reciever email/slack configuration
- kubectl get cm (configmap)  


# For reference youtube - https://www.youtube.com/watch?v=6xmWr7p5TE0
  - https://kodekloud.com/topic/lab-kubernetes-prometheus-2/
# https://medium.com/globant/setup-prometheus-and-grafana-monitoring-on-kubernetes-cluster-using-helm-3484efd85891

                                                             
